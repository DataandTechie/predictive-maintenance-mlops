# %%
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# %%
import os
print(os.getcwd())


# %%
df = pd.read_csv("../data/ai4i2020.csv")
print(df.head())


# %%
df.shape
df.columns
df.info

# %%
df.describe

# %%
# Count how many 0s and 1s in 'Machine failure' column
print(df['Machine failure'].value_counts())

# Show proportions (percentages)
print(df['Machine failure'].value_counts(normalize=True))

# %%
import seaborn as sns
import matplotlib.pyplot as plt

#compute correlation matrix
corr = df.corr(numeric_only=True)

# Draw the heeatmap
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
plt.show()


# %%
import seaborn as sns

# plot distribution of torque for both classes

plt.figure(figsize=(10,5))
sns.boxplot(x='Machine failure', y='Torque [Nm]', data=df)
plt.title('Torque vs Machine Failure')
plt.show()


# %%
sns.boxplot(x='Machine failure', y='Rotational speed [rpm]', data=df)


# %%
# Drop columns
df = df.drop(['Product ID', 'Air temperature [K]'], axis=1)

# Verify changes
df.head()


# %%
# Check the data types of all columns
print(X.dtypes)


# %%
from sklearn.preprocessing import StandardScaler

# 1. Drop UDI (not useful for prediction)
X = X.drop(['UDI'], axis=1)

# 2. One-hot encode the 'Type' column
X = pd.get_dummies(X, columns=['Type'], drop_first=True)

# 3. Scale all numeric features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 4. Convert back to DataFrame for readability
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

# View the result
X_scaled.head()


# %%
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Use the scaled features (X_scaled) and target (y)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

# Fit logistic regression
logreg = LogisticRegression()
logreg.fit(X_train, y_train)

# Predict
y_pred = logreg.predict(X_test)

# Evaluate
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))


# %%
#6B.1:

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# ðŸŽ¯ Target: TWF
y_twf = df['TWF']  # Binary: 0 or 1

# ðŸ”€ Split into training and test sets
X_train_twf, X_test_twf, y_train_twf, y_test_twf = train_test_split(
    X_scaled, y_twf, test_size=0.2, random_state=42, stratify=y_twf
)

# ðŸ§  Train logistic regression model
model_twf = LogisticRegression(class_weight='balanced')
model_twf.fit(X_train_twf, y_train_twf)

# ðŸ“Š Predict and evaluate
y_pred_twf = model_twf.predict(X_test_twf)

print("Classification Report for TWF:")
print(classification_report(y_test_twf, y_pred_twf))


# %%
# ðŸŽ¯ Target: HDF
y_hdf = df['HDF']

# ðŸ”€ Train-test split
X_train_hdf, X_test_hdf, y_train_hdf, y_test_hdf = train_test_split(
    X_scaled, y_hdf, test_size=0.2, random_state=42, stratify=y_hdf
)

# ðŸ§  Train model
model_hdf = LogisticRegression(class_weight='balanced')
model_hdf.fit(X_train_hdf, y_train_hdf)

# ðŸ“Š Evaluate
y_pred_hdf = model_hdf.predict(X_test_hdf)

print("Classification Report for HDF:")
print(classification_report(y_test_hdf, y_pred_hdf))


# %%
# ðŸŽ¯ Target: PWF
y_pwf = df['PWF']

# ðŸ”€ Train-test split
X_train_pwf, X_test_pwf, y_train_pwf, y_test_pwf = train_test_split(
    X_scaled, y_pwf, test_size=0.2, random_state=42, stratify=y_pwf
)

# ðŸ§  Train model
model_pwf = LogisticRegression(class_weight='balanced')
model_pwf.fit(X_train_pwf, y_train_pwf)

# ðŸ“Š Evaluate
y_pred_pwf = model_pwf.predict(X_test_pwf)

print("Classification Report for PWF:")
print(classification_report(y_test_pwf, y_pred_pwf))


# %%
# ðŸŽ¯ Target: OSF
y_osf = df['OSF']

# ðŸ”€ Train-test split
X_train_osf, X_test_osf, y_train_osf, y_test_osf = train_test_split(
    X_scaled, y_osf, test_size=0.2, random_state=42, stratify=y_osf
)

# ðŸ§  Train model
model_osf = LogisticRegression(class_weight='balanced')
model_osf.fit(X_train_osf, y_train_osf)

# ðŸ“Š Evaluate
y_pred_osf = model_osf.predict(X_test_osf)

print("Classification Report for OSF:")
print(classification_report(y_test_osf, y_pred_osf))


# %%
# ðŸŽ¯ Target: RNF
y_rnf = df['RNF']

# ðŸ”€ Train-test split
X_train_rnf, X_test_rnf, y_train_rnf, y_test_rnf = train_test_split(
    X_scaled, y_rnf, test_size=0.2, random_state=42, stratify=y_rnf
)

# ðŸ§  Train model
model_rnf = LogisticRegression(class_weight='balanced')
model_rnf.fit(X_train_rnf, y_train_rnf)

# ðŸ“Š Evaluate
y_pred_rnf = model_rnf.predict(X_test_rnf)

print("Classification Report for RNF:")
print(classification_report(y_test_rnf, y_pred_rnf))


# %%
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# ðŸŽ¯ Binary target (Machine failure)
y_binary = df['Machine failure']

# ðŸ”€ Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_binary, test_size=0.2, random_state=42, stratify=y_binary
)

# ðŸŒ³ Train Random Forest model
rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)
rf_model.fit(X_train, y_train)

# ðŸ§ª Predict
y_pred = rf_model.predict(X_test)

# ðŸ“Š Evaluate
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))


# %%
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# ðŸ”¢ Get predicted probabilities for the positive class
y_probs = rf_model.predict_proba(X_test)[:, 1]

# ðŸ“ˆ Compute ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_probs)

# ðŸ”º Compute AUC
roc_auc = roc_auc_score(y_test, y_probs)

# ðŸ“Š Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'Random Forest (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')  # diagonal reference line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Machine Failure Prediction')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()


# %%
import joblib

# Save the model
joblib.dump(rf_model, '../models/rf_machine_failure_model.pkl')

print("âœ… Model saved successfully!")


# %%
import os
os.makedirs("../models", exist_ok=True)


# %%
loaded_model = joblib.load('../models/rf_machine_failure_model.pkl')



